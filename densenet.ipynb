{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms \n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataset\n",
    "\n",
    "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "\n",
    "# wget did not work for this kaggle notebook, hence i manually downloaded the dataset and uploaded it to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data\n",
    "\n",
    "TRAINING_PATH = \"tiny-imagenet-200/train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.ImageFolder(root = TRAINING_PATH, transform = transform, target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading validation data\n",
    "\n",
    "VAL_PATH = \"tiny-imagenet-200/val\"\n",
    "\n",
    "\n",
    "with open(\"tiny-imagenet-200/val/val_annotations.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "val_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split('\\t')\n",
    "    val_dict[parts[0]] = parts[1]\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "    \n",
    "\n",
    "val_data = datasets.ImageFolder(root = VAL_PATH, transform = transform, target_transform = None)\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    img_path, _ = val_data.imgs[i]\n",
    "    img_name = os.path.basename(img_path)\n",
    "    val_data.imgs[i] = (img_path, training_data.classes.index(val_dict[img_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shapes\n",
    "\n",
    "print(f\"Length of training data = {len(training_data)}, Shape of Image = {training_data[0][0].shape}\")\n",
    "print(f\"Length of validation data = {len(val_data)}, Shape of Image = {val_data[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label mapping file\n",
    "with open(\"tiny-imagenet-200/words.txt\", 'r') as f:\n",
    "    class_names = f.readlines()\n",
    "    \n",
    "# mapping between WordNet IDs to class names\n",
    "class_dict = {}\n",
    "for line in class_names:\n",
    "    line = line.split('\\t')\n",
    "    class_dict[line[0]] = line[1].strip()\n",
    "    \n",
    "    \n",
    "# visualise\n",
    "torch.manual_seed(1234)\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "rows, cols = 3, 3\n",
    "for i in range(rows * cols):\n",
    "    rand_idx = torch.randint(0, len(training_data), size = [1]).item()\n",
    "    image, target = training_data[rand_idx]\n",
    "    fig.add_subplot(rows, cols, i + 1)\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(class_dict[training_data.classes[target]])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "training_dataloader = DataLoader(dataset = training_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(dataset = val_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "training_images, training_targets = next(iter(training_dataloader))\n",
    "\n",
    "print(f\"Training images batch shape = {training_images.shape}\")\n",
    "print(f\"Training targets batch shape = {training_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_config = {\n",
    "            121 : [6, 12, 24, 16],\n",
    "            169 : [6, 12, 32, 32],\n",
    "            201 : [6, 12, 48, 32],\n",
    "            264 : [6, 12, 64, 48]\n",
    "        }\n",
    "\n",
    "        self.k = 32\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_1 = nn.Conv2d(in_channels = 3, out_channels = 2 * self.k, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.dense_blocks = nn.ModuleList([])\n",
    "        self.k_0 = 2 * self.k\n",
    "\n",
    "        for i, l in enumerate(self.block_config[config]):\n",
    "            self.dense_blocks.append(dense_block(num_layers = l, in_channels = self.k_0, growth_rate = self.k))\n",
    "            self.k_0 += self.k * l\n",
    "\n",
    "            if i != len(self.block_config[config]) - 1:\n",
    "                self.dense_blocks.append(transition_layer(in_channels = self.k_0, theta = 0.5))\n",
    "                self.k_0 //= 2\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn2 = nn.BatchNorm2d(self.k_0)\n",
    "        self.global_avgpool = nn.AvgPool2d(kernel_size = 7)\n",
    "        self.fc = nn.Linear(in_features = self.k_0, out_features = num_classes)\n",
    "\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        for layer in self.dense_blocks:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "\n",
    "class dense_block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.ModuleList([])\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.block.append(dense_layer(in_channels = in_channels + (i * growth_rate), growth_rate = growth_rate))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.block:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class transition_layer(nn.Module):\n",
    "    def __init__(self, in_channels, theta):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_1x1 = nn.Conv2d(in_channels = in_channels, out_channels = int(theta * in_channels), kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        return self.avgpool(x)\n",
    "\n",
    "\n",
    "\n",
    "class dense_layer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_1x1 = nn.Conv2d(in_channels = in_channels, out_channels = 4 * growth_rate, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
    "        self.conv_3x3 = nn.Conv2d(in_channels = 4 * growth_rate, out_channels = growth_rate, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_maps = x\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_3x3(x)\n",
    "\n",
    "        return torch.cat([feature_maps, x], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and val metrics \n",
    "\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "epoch_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def model_train(epochs, model, train_dataloader, val_dataloader, loss_func, optimizer, scheduler):\n",
    "\n",
    "    # turn on training mode\n",
    "    model.train()\n",
    "\n",
    "    #check training device\n",
    "    print(f\"Training on {device}.\")\n",
    "\n",
    "    # loop through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}\\n-------------\")\n",
    "\n",
    "        # loop through each batch\n",
    "        train_loss, train_acc = 0, 0\n",
    "        total_steps = 1\n",
    "        for images, classes in train_dataloader:\n",
    "\n",
    "            #send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # computer forward pass\n",
    "            y_pred = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_pred, classes)\n",
    "            train_loss += loss\n",
    "            train_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1))\n",
    "\n",
    "            # update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = train_loss / total_steps\n",
    "            batch_acc = train_acc / total_steps\n",
    "\n",
    "            if total_steps % 10 == 0:\n",
    "                print(f\"Training Loss: {batch_loss:.5f} - Training Accuracy: {batch_acc:.5f}%\")\n",
    "\n",
    "            total_steps += 1\n",
    "\n",
    "        # learning rate decay\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        # performance on test set\n",
    "        # turn on inference mode\n",
    "        with torch.inference_mode():\n",
    "            # loop through each batch\n",
    "            total_val_loss, val_acc = 0, 0\n",
    "            for val_images, val_classes in val_dataloader:\n",
    "                # send data to device\n",
    "                val_images, val_classes = val_images.to(device), val_classes.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                y_val_pred = model(val_images)\n",
    "\n",
    "                # compute loss\n",
    "                val_loss = loss_func(y_val_pred, val_classes)\n",
    "                total_val_loss += val_loss\n",
    "                val_acc += accuracy_fn(y_true = val_classes, y_pred = y_val_pred.argmax(dim=1)\n",
    "                )\n",
    "            \n",
    "            total_val_loss /= len(val_dataloader)\n",
    "            val_acc /= len(val_dataloader)\n",
    "\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "\n",
    "        print(f\"[After {epoch + 1} epochs: Train Loss: {train_loss:.5f} - Train Accuracy: {train_acc:.5f}% - Validation Loss: {total_val_loss:.5f} - Validation Accuracy: {val_acc:.5f}%]\")\n",
    "\n",
    "        \n",
    "        train_loss_values.append(train_loss.item())\n",
    "        val_loss_values.append(total_val_loss.item())\n",
    "        val_acc_values.append(val_acc)\n",
    "        epoch_count.append(epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "\n",
    "def model_test(model, dataloader, loss_func):\n",
    "    # turn on test mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop through each batch\n",
    "        test_loss, test_acc = 0, 0\n",
    "        for images, classes in dataloader:\n",
    "            # send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_pred, classes)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Loss: {test_loss:.5f} - Accuracy: {test_acc:.5f}%\")\n",
    "        return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric functions\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "densenet = DenseNet(num_classes = 200, config = 121).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "sgd = torch.optim.SGD(params = densenet.parameters(), lr = LEARNING_RATE, momentum = 0.9, weight_decay = 0.0001)\n",
    "\n",
    "learning_decay = torch.optim.lr_scheduler.StepLR(optimizer = sgd, step_size = 30, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "EPOCHS = 90\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "model_train(epochs = EPOCHS, model = densenet, train_dataloader = training_dataloader, val_dataloader = val_dataloader, loss_func = loss_func, optimizer = sgd, scheduler = learning_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model\n",
    "\n",
    "accuracy = model_test(model = resnet, dataloader = val_dataloader, loss_func = loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, train_loss_values, label = \"Train loss\")\n",
    "plt.plot(epoch_count, val_loss_values, label = \"Validation loss\")\n",
    "plt.title(\"Loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, val_acc_values, label = \"Accuracy\")\n",
    "plt.title(\"Accuracy curves\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "MODEL_NAME = \"DenseNet_\" + str(accuracy).replace(\".\", \"_\") + \".pth\"\n",
    "\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving DenseNet to {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj = dense.state_dict(), f = MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
